{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "154bd63a-27be-4a52-811f-647876964a13",
   "metadata": {},
   "source": [
    "#### This script sends an authenticated HTTP/GET request to a specified URL, retrieves XML data, processes it into a Pandas DataFrame, and then prints the DataFrame. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cc7c88-0c36-4670-846e-9762ec165d0f",
   "metadata": {},
   "source": [
    "##### With 'Requests' we make direct requests to the API endpoints. This is a clean and efficient approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2501243f-485c-427b-abb5-8c903dabb68a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests_ntlm import HttpNtlmAuth\n",
    "import getpass\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "56ed7a98-f532-4114-b514-74dbcc449a95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Suppress all warnings from urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "72817832-1b59-45d1-b179-31fc3bbd4042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_authenticated_request(base_url,report_id,username,password):\n",
    "    try:\n",
    "         # Construct the full URL with the dynamic report_id\n",
    "        url = f\"{base_url}{report_id}\"\n",
    "\n",
    "        # Create an instance of HttpNtlmAuth with username and password\n",
    "        auth = HttpNtlmAuth(username, password)\n",
    "\n",
    "        # Make an HTTP GET request with SSL verification disabled, NTLM authentication, and a timeout of 20 seconds\n",
    "        response = requests.get(url, verify=False, auth=auth, timeout=30)\n",
    "\n",
    "        # Check if the request was successful (status code 200)\n",
    "        if response.status_code == 200:\n",
    "            xml_data = response.text\n",
    "            df = pd.read_xml(xml_data)\n",
    "            #print(df)\n",
    "            df.to_excel(r\"C:\\Users\\Maria.diapouli\\OneDrive - OFWAT\\Python\\validation_tool\\Model Firing Order\\\\\" + report_id + \"_Fountain_data.xlsx\", sheet_name=\"F_Outputs\", index=False)\n",
    "            print(\"Data downloaded - Completed OK\")\n",
    "        elif response.status_code == 409:\n",
    "            # The specific message is in the response; prompt user for company ID\n",
    "            company_id = input(\"This report has no company, please enter a company ID: \")\n",
    "            # You can use the company_id in further processing or make another request with the company_id\n",
    "            print(f\"Company ID entered: {company_id}\")\n",
    "        else:\n",
    "            print(f\"Failed to retrieve data. Status code: {response.status_code}\")\n",
    "            print(\"Response content:\")\n",
    "            print(response.text)\n",
    "#catches any exception that inherits from RequestException. If any exception occurs during the execution of the try block (e.g., network issues, timeouts, or other HTTP-related errors, TooManyRedirects), \n",
    "#it will be caught here, and the program will print an error message indicating that an error occurred.\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "be015d3e-d995-478d-b980-e5afb55a7abd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the report ID:  22396\n",
      "Enter your email address:  maria.diapouli@ofwat.gov.uk\n",
      "Enter your password:  ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data downloaded - Completed OK\n",
      "CPU times: total: 188 ms\n",
      "Wall time: 13.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "base_url = \"https://fountain01/Fountain/rest-services/report/flattable/\"\n",
    "#Prompt the user to enter their email address and password\n",
    "report_id = input(\"Enter the report ID: \")\n",
    "username = input(\"Enter your email address: \")\n",
    "password = getpass.getpass(\"Enter your password: \")\n",
    "make_authenticated_request(base_url,report_id,username,password)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07f8087-5888-4dd4-9f84-73542cc2606c",
   "metadata": {},
   "source": [
    "### Dataframe Validation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab675a7-7acc-47e7-81a3-9d43d6da2a4b",
   "metadata": {},
   "source": [
    "#### When comparing two dataframes in Python to find any differences (rows with different values), we need to perform data validation to ensure a meaningful and accurate comparison. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2982a023-a95b-48cf-9fbe-d9bdb9d6923d",
   "metadata": {},
   "source": [
    "1. Check Column Names (Headers): Ensure that the column names in both dataframes are the same. \n",
    "2. Check Data Types: Verify that the data types of corresponding columns are the same. Mismatched data types can lead to inaccurate comparisons.\n",
    "3. Check Shape of Dataframes: Ensure that the shape of the dataframes is the same, i.e., the number of rows and columns matches.\n",
    "4. Remove Duplicates: Check for and remove any duplicate rows in both dataframes.\n",
    "5. Sort Dataframes: Sorting dataframes can help ensure that the rows are in the same order, for accurate comparison.\n",
    "6. Reset Index: Reset the index after sorting to ensure that it starts from 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8b54698-9a96-4f44-a116-f913d36e2c8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate_and_compare_dataframes(df1, df2):\n",
    "    error_messages = []\n",
    "    differing_rows = None\n",
    "\n",
    "    # Check column names\n",
    "    if df1.columns.tolist() != df2.columns.tolist():\n",
    "        error_messages.append(\"Column names in the dataframes are not identical.\")\n",
    "        \n",
    "    # Check data types\n",
    "    if df1.dtypes.to_dict() != df2.dtypes.to_dict():\n",
    "        error_messages.append(\"Data types of columns are not identical.\")\n",
    "    \n",
    "    # Check shape of dataframes\n",
    "    if df1.shape != df2.shape:\n",
    "        error_messages.append(\"Shapes of the dataframes do not match.\")\n",
    "    \n",
    "    # Remove duplicates\n",
    "    df1 = df1.drop_duplicates()\n",
    "    df2 = df2.drop_duplicates()\n",
    "\n",
    "    # Sort dataframes\n",
    "    df1 = df1.sort_values(by=df1.columns.tolist())\n",
    "    df2 = df2.sort_values(by=df2.columns.tolist())\n",
    "\n",
    "    # Reset index\n",
    "    df1 = df1.reset_index(drop=True)\n",
    "    df2 = df2.reset_index(drop=True)\n",
    "\n",
    "    # Raise a single exception with all error messages and differing rows\n",
    "    if error_messages or differing_rows is not None:\n",
    "        raise ValueError(\"\\n\".join(error_messages), differing_rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1583f9e2-e357-4be4-ab6a-04907cfc77cb",
   "metadata": {},
   "source": [
    "### Dataframe Standardization \n",
    "#### Data standardization is the process of transforming data into a common format or structure to facilitate comparison. In the context of comparing data between two DataFrames, standardization will involve: \n",
    "1. converting data types\n",
    "2. rounding numeric values\n",
    "3. deleting rows to ensure consistent formatting\n",
    "4. ensure column name consistent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8ca925c-d2b4-4c16-a209-1e6a2d4c9254",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Testing Fountain report always request 4 items so we expect data to start from row 5\n",
    "def df_fountain_standardization(df):\n",
    "    # Drop the first column\n",
    "    df = df.drop(df.columns[0], axis=1)\n",
    "    # Get values from cells G3, G4, G5 and save them as attributes\n",
    "    attributes = df.iloc[2:5, 6].tolist()\n",
    "    print('Fountain Attributes from Report are: ',attributes)\n",
    "    # Assign columns on row 1\n",
    "    df.columns = (df.iloc[1])\n",
    "    # Remove rows \n",
    "    df = df.drop([0, 1, 2, 3,4])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "395b7671-98dd-41c2-9362-cd05618ea947",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def df_excel_model_standardization(df):\n",
    "    report_name = df.iloc[0,2]\n",
    "    print('Report name is: ',report_name)\n",
    "    # Assign columns on row 1\n",
    "    df.columns = (df.iloc[1])\n",
    "    df = df.drop([0])\n",
    "    df = df.drop([1,2])\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6aefda8-d306-47da-9dc0-1f13d0b8ac93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compare_column_names(df1, df2):\n",
    "    # Extract column names\n",
    "    column_names_df1 = df1.columns.tolist()\n",
    "    column_names_df2 = df2.columns.tolist()\n",
    "\n",
    "    # Compare column names\n",
    "    different_columns = set(column_names_df1) ^ set(column_names_df2)\n",
    "\n",
    "    if different_columns:\n",
    "        print(\"Differing column names:\")\n",
    "        for column in different_columns:\n",
    "            if column in column_names_df1:\n",
    "                print(f\"Column: {column}, Values in df1: {df1[column].tolist()}\")\n",
    "            if column in column_names_df2:\n",
    "                print(f\"Column: {column}, Values in df2: {df2[column].tolist()}\")\n",
    "    else:\n",
    "        print(\"*Column names are the same for both DataFrames.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f9c442-bcd2-417a-9fd1-2ed1fb5e0e23",
   "metadata": {},
   "source": [
    "###  Dataframe Comparison. \n",
    "#### Using the merge function in pandas to identify rows that exist in one DataFrame but not in the other. The merge function is used to merge df1 and df2, the '_merge' column is added to indicate the source of each row (when value is both it means that data exist in both dataframes). The differing_rows DataFrame contains rows that are unique to either df1 or df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5595c7e3-cfcf-4b95-8aac-3c5a7df90dc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sort_dataframe(df, columns):\n",
    "    return df.sort_values(by=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e32245a-728b-489e-a6a5-52cd1470fd6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_differing_rows(df1, df2):\n",
    "\n",
    "    # Merge DataFrames and identify differing rows\n",
    "    merged_df = pd.merge(df1, df2, how='outer', indicator=True)\n",
    "    # Select rows that are different\n",
    "    different_rows = merged_df[merged_df['_merge'] != 'both']\n",
    "\n",
    "    # Drop the indicator column\n",
    "    different_rows = different_rows.drop(columns=['_merge'])\n",
    "\n",
    "    return different_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "239ec0ce-d0cf-44f6-a5ef-be2afe76ec6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_numeric(value):\n",
    "    try:\n",
    "        return round(pd.to_numeric(value),6)\n",
    "    except (ValueError, TypeError):\n",
    "        return str(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3c87c7e-5358-4750-bc80-1fc6c66ede8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fountain Attributes from Report are:  ['Price Review 2019', 'PR19 Run 8A: 7 November draft FD', 'Latest']\n",
      "Report name is:  PR19CA008_OUT2\n",
      "*Column names are the same for both DataFrames.\n",
      "**Dataframes Validation Completed.\n",
      "CPU times: total: 438 ms\n",
      "Wall time: 457 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "path = r\"C:\\Users\\Maria.diapouli\\OneDrive - OFWAT\\Python\\validation_tool\\Model Firing Order\\Examples\"\n",
    "os.chdir(path)  # Change the directory to the O drive\n",
    "\n",
    "file_name1='22396_Fountain_data.xlsx'\n",
    "file_name2='22396_FM_WWW4_Run8a.xlsx'\n",
    "\n",
    "# Extract base name without extension\n",
    "# Extract base name without extension\n",
    "base_name1 = os.path.splitext(file_name1)[0]\n",
    "base_name2 = os.path.splitext(file_name2)[0]\n",
    "\n",
    "# Load data\n",
    "df1 = pd.read_excel(file_name1, sheet_name='F_Outputs',header=None)\n",
    "df2 = pd.read_excel(file_name2, sheet_name='F_Outputs',header=None)\n",
    "\n",
    "df1 = df_fountain_standardization(df1)\n",
    "#.sort_values(by=['Acronym', 'Reference'])\n",
    "df2 = df_excel_model_standardization(df2)\n",
    "\n",
    "############\n",
    "#Standardized Column Names\n",
    "# Extract column names from the first row\n",
    "column_names_df1 = df1.columns.tolist()\n",
    "column_names_df2 = df2.columns.tolist()\n",
    "\n",
    "# New column names for the first 5 columns\n",
    "common_columns = ['Acronym', 'Reference', 'Item description', 'Unit', 'Model']\n",
    "\n",
    "# Assign new column names for first 5 columns of df, and renames them based on the provided mapping (common_columns). The rest of the column names beyond the first 5 columns will remain unchanged.\n",
    "df1.rename(columns=dict(zip(column_names_df1[:5], common_columns)), inplace=True)\n",
    "df2.rename(columns=dict(zip(column_names_df2[:5], common_columns)), inplace=True)\n",
    "\n",
    "compare_column_names(df1, df2)\n",
    "\n",
    "##Sort dataframes\n",
    "# Specify columns for sorting\n",
    "sort_columns = ['Acronym', 'Reference']\n",
    "df1 = sort_dataframe(df1, sort_columns)\n",
    "df2 = sort_dataframe(df2, sort_columns)\n",
    "\n",
    "##Dataframe Validation\n",
    "try:\n",
    "    validate_and_compare_dataframes(df1, df2)\n",
    "    print(\"**Dataframes Validation Completed.\")\n",
    "except ValueError as e:\n",
    "    error_message, differing_rows = e.args\n",
    "    print(f\"Validation failed:\\n{error_message}\")\n",
    "\n",
    "# Due to the way Fountain stores represent floating-point numbers, comparing them directly for equality may lead to unexpected results due to rounding errors.Rounding the values to 6 decimal places.\n",
    "# Convert values in columns 5 and beyond to numeric\n",
    "df1.iloc[:, 5:] = df1.iloc[:, 5:].applymap(convert_to_numeric)\n",
    "df2.iloc[:, 5:] = df2.iloc[:, 5:].applymap(convert_to_numeric)\n",
    "\n",
    "\n",
    "\n",
    "df1.to_excel(os.path.join(\".\\\\Outputs\\\\\" , base_name1 + \"_Standardized.xlsx\"), sheet_name=\"F_Outputs\", index=False)\n",
    "df2.to_excel(os.path.join(\".\\\\Outputs\\\\\" , base_name2 +\"_Standardized.xlsx\"), sheet_name=\"F_Outputs\", index=False)\n",
    "\n",
    "df_differing_rows = find_differing_rows(df1, df2)\n",
    "df_differing_rows = sort_dataframe(df_differing_rows, sort_columns)\n",
    "df_differing_rows.drop_duplicates()\n",
    "df_differing_rows.to_excel(os.path.join(\".\\\\Outputs\\\\\" , \"differing_rows.xlsx\"), sheet_name=\"F_Outputs\",  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7086965-12b4-4b4b-a51f-ca7dba9b0f64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4231758f-6c20-4c1b-b76c-82ff41554430",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
